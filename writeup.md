In this ETL project, useful information for all drugs in the FDA database was downloaded from http://accessdata.fda.gov in the form of CSV tables. In these two tables, information such as the drugs NDC, brand name, generic name, formulation, and route of administration, as a few examples, was split between them. There was a unique identifier between the two tables, a column called �product_id�, that we could later use as primary key�s and join together on in a PostgreSQL database.

To begin the project, the goal was to build a pandas data-frame for each of our two CSV files with column names more useful for us. To do this, a data-frame for each table was built where any duplicate �product_id� values existed, which were none. All of the columns were renamed using a dictionary within the pd.rename function. The final data-frames, with �product_id� as the index, were restructured to both contain the useful data we wanted and to rid of overlapping columns of data.

With the structure of our tables figured, we first created a database for this project in my PostgreSQL local server. Using SQL statements, we built the two tables that will contain the data from the data-frames we created. Using SQLalchemy, we connected to a local PostgreSQL database and verified the connection using engine.table_names() with the expectation of seeing the titles of the two tables we made previously. Using pd.to_sql, this connection was used to finally upload the data-frame to the PostgreSQL server. In order to fill some null values with information more important to us, such as the �dea_schedule� table, two update SQL statements were used to replace �dea_schedule� null values with CVI when �product_type_name� contained the word �prescription� and OTC when �product_type_name� contained the word �OTC�. A final query was performed inner joining the two tables on �product_id�.
